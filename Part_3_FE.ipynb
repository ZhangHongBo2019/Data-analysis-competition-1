{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm\n",
    "import scipy.stats as sta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--train and test data--\n",
    "train_df = pd.read_csv('D:/DataAnalysis/2019未来高校AI挑战赛_城市-房产租金预测/train_data.csv')\n",
    "test_df = pd.read_csv('D:/DataAnalysis/2019未来高校AI挑战赛_城市-房产租金预测/test_a.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41440, 51)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proprecessing(train_df,test_df):\n",
    "    \n",
    "    ## fill with null values\n",
    "    fill_na = [\"uv\",\"pv\"]\n",
    "    for fill in fill_na:\n",
    "        train_df[fill].fillna(train_df[fill].mean(),inplace=True)\n",
    "        test_df[fill].fillna(test_df[fill].mean(),inplace=True)\n",
    "        train_df[fill] = train_df[fill].astype(int)\n",
    "        test_df[fill] = test_df[fill].astype(int)\n",
    "        \n",
    "    ## 使用孤立森林来检测tradeMoney的异常值点\n",
    "    from sklearn.ensemble import IsolationForest\n",
    "    IForest = IsolationForest(contamination=0.02)\n",
    "    IForest.fit(train_df['tradeMoney'].values.reshape(-1,1))\n",
    "    ypred = IForest.predict(train_df['tradeMoney'].values.reshape(-1,1))\n",
    "    drop_index = train_df[ypred==-1].index\n",
    "    train_df.drop(drop_index,axis=0,inplace=True)\n",
    "    \n",
    "    ##--area--\n",
    "    train_df = train_df[(train_df['area']>=10)&(train_df['area']<=200)]\n",
    "    \n",
    "    ##组合特征进行筛选\n",
    "    #list(train_df[['region','tradeMoney','area']].groupby('region'))\n",
    "    train_df.drop(train_df[(train_df['region']=='RG00001')&(train_df['area']>=100)&\n",
    "                       (train_df['tradeMoney']<=2000)].index,inplace=True)\n",
    "    # train_df.drop(train_df[(train_df['region']=='RG00001')&(train_df['area']<=10)&\n",
    "    #                     (train_df['tradeMoney']>=3000)].index,inplace=True)\n",
    "    train_df.drop(train_df[(train_df['region']=='RG00002')&(train_df['area']>=100)&\n",
    "                           (train_df['tradeMoney']<=1000)].index,inplace=True)\n",
    "    # train_df.drop(train_df[(train_df['region']=='RG00003')&(train_df['area']<=10)&\n",
    "    #                        (train_df['tradeMoney']>=4000)].index,inplace=True)\n",
    "    train_df.drop(train_df[(train_df['region']=='RG00003')&(train_df['area']>=150)&\n",
    "                           (train_df['tradeMoney']<=2000)].index,inplace=True)\n",
    "    train_df.drop(train_df[(train_df['region']=='RG00004')&(train_df['area']>=100)&\n",
    "                           (train_df['tradeMoney']<=1000)].index,inplace=True)\n",
    "    train_df.drop(train_df[(train_df['region']=='RG00005')&(train_df['area']>=150)&\n",
    "                           (train_df['tradeMoney']<=2000)].index,inplace=True)\n",
    "    train_df.drop(train_df[(train_df['region']=='RG00006')&(train_df['area']>=100)&\n",
    "                           (train_df['tradeMoney']<1000)].index,inplace=True)\n",
    "    train_df.drop(train_df[(train_df['region']=='RG00008')&(train_df['area']>100)&\n",
    "                           (train_df['tradeMoney']<=2000)].index,inplace=True)\n",
    "    train_df.drop(train_df[(train_df['region']=='RG00009')&(train_df['area']>=100)&\n",
    "                           (train_df['tradeMoney']<=1000)].index,inplace=True)\n",
    "    # train_df.drop(train_df[(train_df['region']=='RG00010')&(train_df['area']>=100)&\n",
    "    #                        (train_df['tradeMoney']<=2000)].index,inplace=True)\n",
    "    train_df.drop(train_df[(train_df['region']=='RG00011')&(train_df['area']>=150)&\n",
    "                           (train_df['tradeMoney']<=2000)].index,inplace=True)\n",
    "    \n",
    "    data_df = pd.concat([train_df,test_df])\n",
    "    data_df.drop(['city','ID','tradeMoney'],axis=1,inplace=True)\n",
    "    \n",
    "    #--rentType--\n",
    "    data_df['rentType'].replace('--','未知方式',inplace=True)\n",
    "\n",
    "    #--buildYear--\n",
    "    median_build = data_df.loc[data_df['buildYear']!='暂无信息','buildYear'].median()\n",
    "    data_df['buildYear'].replace(\"暂无信息\",median_build,inplace=True)\n",
    "    data_df['buildYear'] = data_df[\"buildYear\"].astype(int)\n",
    "    #data_df[\"buildYear\"] = 2019-data_df[\"buildYear\"]\n",
    "\n",
    "    #--houseType--\n",
    "    data_df['rooms'] = data_df['houseType'].apply(lambda x:x.split('室')[0][-1]).astype(int)\n",
    "    data_df['halls'] = data_df['houseType'].apply(lambda x:x.split('厅')[0][-1]).astype(int)\n",
    "    data_df['bathrooms'] = data_df['houseType'].apply(lambda x:x.split('卫')[0][-1]).astype(int)\n",
    "    data_df['rooms_bathrooms'] = (data_df['bathrooms']+1)/(data_df['rooms']+1)\n",
    "    data_df['rooms_bathrooms'] = data_df['rooms_bathrooms'].astype(int)\n",
    "    data_df.drop('houseType',axis=1,inplace=True)\n",
    "    \n",
    "    #--tradeTime--\n",
    "    data_df['Month'] = data_df['tradeTime'].apply(lambda x:x.split('/')[1]).astype(int)\n",
    "    data_df['Date'] = data_df['tradeTime'].apply(lambda x:x.split('/')[2]).astype(int) \n",
    "    data_df.drop('tradeTime',axis=1,inplace=True)\n",
    "    \n",
    "    return train_df,data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AnacondaSoftware\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\iforest.py:417: DeprecationWarning: threshold_ attribute is deprecated in 0.20 and will be removed in 0.22.\n",
      "  \" be removed in 0.22.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "train_df,data_df = proprecessing(train_df,test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df['interSchoolNum'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df['privateSchoolNum'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df['schoolNum'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 关于数据的分析，前2个脚本已经很详细了，这里重点在于特征的处理上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['area',\n",
       " 'bankNum',\n",
       " 'buildYear',\n",
       " 'busStationNum',\n",
       " 'drugStoreNum',\n",
       " 'gymNum',\n",
       " 'hospitalNum',\n",
       " 'interSchoolNum',\n",
       " 'landMeanPrice',\n",
       " 'landTotalPrice',\n",
       " 'lookNum',\n",
       " 'mallNum',\n",
       " 'newWorkers',\n",
       " 'parkNum',\n",
       " 'privateSchoolNum',\n",
       " 'pv',\n",
       " 'remainNewNum',\n",
       " 'residentPopulation',\n",
       " 'saleSecHouseNum',\n",
       " 'schoolNum',\n",
       " 'shopNum',\n",
       " 'subwayStationNum',\n",
       " 'superMarketNum',\n",
       " 'supplyLandArea',\n",
       " 'supplyLandNum',\n",
       " 'supplyNewNum',\n",
       " 'totalFloor',\n",
       " 'totalNewTradeArea',\n",
       " 'totalNewTradeMoney',\n",
       " 'totalTradeArea',\n",
       " 'totalTradeMoney',\n",
       " 'totalWorkers',\n",
       " 'tradeLandArea',\n",
       " 'tradeLandNum',\n",
       " 'tradeMeanPrice',\n",
       " 'tradeNewMeanPrice',\n",
       " 'tradeNewNum',\n",
       " 'tradeSecNum',\n",
       " 'uv',\n",
       " 'rooms',\n",
       " 'halls',\n",
       " 'bathrooms',\n",
       " 'rooms_bathrooms',\n",
       " 'Month',\n",
       " 'Date']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_col = [col for col in data_df.columns if data_df[col].dtypes!='object']\n",
    "numerical_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##--Supporting facilities--\n",
    "data_df['All_School'] = 2*data_df['interSchoolNum']/data_df['interSchoolNum'].mean() + (\n",
    "    data_df['privateSchoolNum']/data_df['privateSchoolNum'].mean()+\n",
    "    data_df['schoolNum']/data_df['schoolNum'].mean())\n",
    "data_df['Transportation'] = 5*data_df['subwayStationNum']/data_df['subwayStationNum'].mean() + data_df['busStationNum']/data_df['busStationNum'].mean()\n",
    "data_df['All_hospital'] = 3*data_df['hospitalNum']/data_df['hospitalNum'].mean()+data_df['drugStoreNum']/data_df['drugStoreNum'].mean()\n",
    "data_df['All_mall'] = data_df['mallNum']/data_df['mallNum'].mean()+data_df['superMarketNum']/data_df['superMarketNum'].mean()\n",
    "data_df['other_num'] = data_df['bankNum']/data_df['bankNum'].mean() + (\n",
    "    data_df['gymNum']/data_df['gymNum'].mean()+data_df['parkNum']/data_df['parkNum'].mean()\n",
    "    +data_df['shopNum']/data_df['shopNum'].mean())\n",
    "data_df.drop(['subwayStationNum', 'busStationNum',\n",
    "               'interSchoolNum', 'schoolNum', 'privateSchoolNum',\n",
    "               'hospitalNum', 'drugStoreNum', 'mallNum', 'superMarketNum', \n",
    "              'gymNum', 'bankNum', 'shopNum', 'parkNum'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.concat([data_df['landTotalPrice'],data_df['tradeLandArea']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--Land--\n",
    "data_df['SecMeanArea'] = data_df['totalTradeArea']/data_df['tradeSecNum']\n",
    "data_df['SecMeanArea'].replace(np.inf,0,inplace=True)\n",
    "data_df['trade_supplyNew_rate'] = data_df['tradeNewNum']/data_df['supplyNewNum']\n",
    "data_df['trade_supplyNew_rate'].replace(np.inf,0,inplace=True)\n",
    "data_df['remain_supply_rate'] = data_df['remainNewNum']/data_df['supplyNewNum']\n",
    "data_df['remain_supply_rate'].replace(np.inf,0,inplace=True)\n",
    "data_df['trade_supplyLand_rate'] = data_df['tradeLandArea']/data_df['supplyLandArea']\n",
    "data_df['trade_supplyLand_rate'].fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "##--group by--\n",
    "inter = data_df.groupby('communityName')['area'].agg({'com_area_mean':'mean','com_area_std':'std'})\n",
    "inter.fillna(0,inplace=True)\n",
    "data_df = data_df.merge(inter,on='communityName',how='left')\n",
    "\n",
    "# data_df['com_area_mean_1'] = data_df.groupby('communityName')['area'].transform('mean')\n",
    "\n",
    "inter = data_df.groupby('plate')['area'].agg({'pla_are_mean':'mean','pla_are_std':'std'})\n",
    "data_df = data_df.merge(inter,on='plate',how='left')\n",
    "#--buildYear--\n",
    "inter = data_df.groupby('plate')['buildYear'].agg({'pla_build_mean':'mean','pla_build_std':'std'})\n",
    "data_df = data_df.merge(inter,on='plate',how='left')\n",
    "data_df.pla_build_mean = data_df.pla_build_mean.astype(int)\n",
    "data_df['pla_build_diff'] = data_df.buildYear - data_df.pla_build_mean\n",
    "#--school--\n",
    "data_df['plate_school'] = data_df.groupby('plate')['All_School'].transform('sum')\n",
    "data_df['commit_plate_school'] = data_df.groupby(['communityName','plate'])['All_School'].transform('sum')\n",
    "data_df['school_ratio'] = data_df['commit_plate_school']/data_df['plate_school']\n",
    "data_df['school_ratio'].replace(np.inf,-1,inplace=True)\n",
    "#--Transportation--\n",
    "data_df['plate_Transp'] = data_df.groupby('plate')['Transportation'].transform('sum')\n",
    "data_df['commit_plate_Transp'] = data_df.groupby(['communityName','plate'])['Transportation'].transform('sum')\n",
    "data_df['Transportation_ratio'] = data_df['commit_plate_Transp']/data_df['plate_Transp']\n",
    "data_df['Transportation_ratio'].replace(np.inf,-1,inplace=True)\n",
    "#--hospital--\n",
    "data_df['plate_hospital'] = data_df.groupby('plate')['All_hospital'].transform('sum')\n",
    "data_df['commit_plate_hospital'] = data_df.groupby(['communityName','plate'])['All_hospital'].transform('sum')\n",
    "data_df['School_ratio'] = data_df['commit_plate_hospital']/data_df['plate_hospital']\n",
    "data_df['School_ratio'].replace(np.inf,-1,inplace=True)\n",
    "#--mall--\n",
    "data_df['plate_mall'] = data_df.groupby('plate')['All_mall'].transform('sum')\n",
    "data_df['commit_plate_mall'] = data_df.groupby(['communityName','plate'])['All_mall'].transform('sum')\n",
    "data_df['mall_ratio'] = data_df['commit_plate_mall']/data_df['plate_mall']\n",
    "data_df['mall_ratio'].replace(np.inf,-1,inplace=True)\n",
    "#--other_num--\n",
    "data_df['plate_other_num'] = data_df.groupby('plate')['other_num'].transform('sum')\n",
    "data_df['commit_plate_other'] = data_df.groupby(['communityName','plate'])['other_num'].transform('sum')\n",
    "data_df['other_ratio'] = data_df['commit_plate_other']/data_df['plate_other_num']\n",
    "data_df['other_ratio'].replace(np.inf,-1,inplace=True)\n",
    "data_df.drop(['pla_build_mean','plate_school','commit_plate_school','plate_Transp','commit_plate_Transp',\n",
    "              'plate_hospital','commit_plate_hospital','plate_mall','commit_plate_mall','plate_other_num',\n",
    "             'commit_plate_other'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster聚类分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "Label_list = ['plate','region','houseToward','communityName','houseDecoration','rentType','houseFloor']\n",
    "for col_4 in Label_list:\n",
    "    data_df[col_4] = data_df[col_4].astype(str)\n",
    "    data_df[col_4] = LabelEncoder().fit_transform(data_df[col_4])\n",
    "    \n",
    "# Onehot_list = ['houseDecoration','rentType','houseFloor']\n",
    "# for col_5 in Onehot_list:\n",
    "#     data_df[col_5] = data_df[col_5].astype(str)\n",
    "#     inter_col = pd.get_dummies(data_df[col_5])\n",
    "#     data_df.drop(col_5,axis=1,inplace=True)\n",
    "#     data_df = pd.concat([data_df,inter_col],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "gmm = GaussianMixture(n_components=5,covariance_type='full',random_state=2019)\n",
    "cluster_col = ['communityName','buildYear','plate','region','landMeanPrice','lookNum','newWorkers',\n",
    "               'residentPopulation','totalFloor','houseDecoration','tradeMeanPrice','tradeSecNum',\n",
    "              'totalNewTradeMoney','totalNewTradeArea','tradeNewMeanPrice','tradeNewNum','remainNewNum',\n",
    "              'landTotalPrice','landMeanPrice','totalWorkers','All_School','Transportation','All_hospital',\n",
    "              'All_mall','other_num']\n",
    "data_df['cluster'] = gmm.fit_predict(data_df[cluster_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_col_2 = ['totalFloor','houseDecoration','communityName','region','plate','buildYear','All_School',\n",
    "                 'Transportation','All_hospital','All_mall','other_num']\n",
    "for i in range(len(cluster_col_2)):\n",
    "    for j in range(i+1,len(cluster_col_2)):\n",
    "        data_df[cluster_col_2[i]+'_'+cluster_col_2[j]] = data_df.groupby(['cluster',\n",
    "                                                                          cluster_col_2[i]])[cluster_col_2[j]].transform('mean')\n",
    "        data_df[cluster_col_2[i]+'_'+cluster_col_2[j]].fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -----------------------------------------baseline---------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "area                              9768\n",
       "communityName                     4035\n",
       "com_area_mean                     3729\n",
       "com_area_std                      3108\n",
       "other_ratio                       1331\n",
       "Transportation_ratio              1331\n",
       "School_ratio                      1331\n",
       "mall_ratio                        1331\n",
       "school_ratio                      1329\n",
       "pv                                 714\n",
       "tradeMeanPrice                     707\n",
       "totalTradeArea                     707\n",
       "totalTradeMoney                    706\n",
       "SecMeanArea                        706\n",
       "uv                                 653\n",
       "totalNewTradeMoney                 561\n",
       "tradeNewMeanPrice                  560\n",
       "totalNewTradeArea                  535\n",
       "remainNewNum                       393\n",
       "communityName_All_mall             340\n",
       "tradeSecNum                        334\n",
       "communityName_Transportation       329\n",
       "communityName_All_School           319\n",
       "communityName_other_num            316\n",
       "communityName_All_hospital         303\n",
       "buildYear_All_mall                 215\n",
       "buildYear_All_School               214\n",
       "buildYear_Transportation           213\n",
       "buildYear_other_num                213\n",
       "buildYear_All_hospital             212\n",
       "                                  ... \n",
       "region_Transportation               41\n",
       "region_All_hospital                 41\n",
       "region_plate                        40\n",
       "lookNum                             32\n",
       "Date                                31\n",
       "saleSecHouseNum                     28\n",
       "trade_supplyLand_rate               21\n",
       "houseDecoration_region              19\n",
       "houseDecoration_plate               19\n",
       "houseDecoration_buildYear           19\n",
       "houseDecoration_All_School          19\n",
       "houseDecoration_Transportation      19\n",
       "houseDecoration_communityName       19\n",
       "houseDecoration_All_hospital        19\n",
       "houseDecoration_other_num           19\n",
       "houseDecoration_All_mall            19\n",
       "communityName_region                15\n",
       "region                              15\n",
       "Month                               12\n",
       "houseToward                         10\n",
       "bathrooms                            8\n",
       "rooms                                7\n",
       "cluster                              5\n",
       "halls                                5\n",
       "tradeLandNum                         5\n",
       "supplyLandNum                        4\n",
       "houseDecoration                      4\n",
       "rentType                             3\n",
       "houseFloor                           3\n",
       "rooms_bathrooms                      2\n",
       "Length: 115, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_new = [col for col in data_df.columns if data_df[col].dtypes!='object']\n",
    "data_df[categorical_new].nunique().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Label_list = ['plate','region','houseToward']\n",
    "# for col_4 in Label_list:\n",
    "#     data_df[col_4] = data_df[col_4].astype(str)\n",
    "#     data_df[col_4] = LabelEncoder().fit_transform(data_df[col_4])\n",
    "    \n",
    "# Onehot_list = ['houseDecoration','rentType','houseFloor']\n",
    "# for col_5 in Onehot_list:\n",
    "#     data_df[col_5] = data_df[col_5].astype(str)\n",
    "#     inter_col = pd.get_dummies(data_df[col_5])\n",
    "#     data_df.drop(col_5,axis=1,inplace=True)\n",
    "#     data_df = pd.concat([data_df,inter_col],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41676, 115)\n",
      "(39207, 51)\n",
      "(2469, 50)\n"
     ]
    }
   ],
   "source": [
    "print(data_df.shape)\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = train_df['tradeMoney']\n",
    "m = len(Y)\n",
    "X = data_df.iloc[:m,:]\n",
    "X_test = data_df.iloc[m:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39207, 115)\n",
      "(2469, 115)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import KFold,cross_val_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'num_leaves': 31,\n",
    "    'min_data_in_leaf': 20,\n",
    "    'min_child_samples':20,\n",
    "    'objective': 'regression',\n",
    "    'learning_rate': 0.01,\n",
    "    \"boosting\": \"gbdt\",\n",
    "    \"feature_fraction\": 0.8,\n",
    "    \"bagging_freq\": 1,\n",
    "    \"bagging_fraction\": 0.85,\n",
    "    \"bagging_seed\": 23,\n",
    "    \"metric\": 'rmse',\n",
    "    \"lambda_l1\": 0.2,\n",
    "    \"nthread\": 4,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°0\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 824.459\tvalid_1's rmse: 949.572\n",
      "[1000]\ttraining's rmse: 729.654\tvalid_1's rmse: 894.288\n",
      "[1500]\ttraining's rmse: 673.99\tvalid_1's rmse: 872.255\n",
      "[2000]\ttraining's rmse: 632.804\tvalid_1's rmse: 858.684\n",
      "[2500]\ttraining's rmse: 600.666\tvalid_1's rmse: 850.315\n",
      "[3000]\ttraining's rmse: 573.618\tvalid_1's rmse: 844.205\n",
      "[3500]\ttraining's rmse: 550.433\tvalid_1's rmse: 839.369\n",
      "[4000]\ttraining's rmse: 530.046\tvalid_1's rmse: 835.968\n",
      "[4500]\ttraining's rmse: 512.324\tvalid_1's rmse: 833.959\n",
      "[5000]\ttraining's rmse: 495.582\tvalid_1's rmse: 831.752\n",
      "[5500]\ttraining's rmse: 480.683\tvalid_1's rmse: 830.236\n",
      "[6000]\ttraining's rmse: 466.707\tvalid_1's rmse: 829.449\n",
      "[6500]\ttraining's rmse: 453.866\tvalid_1's rmse: 828.586\n",
      "[7000]\ttraining's rmse: 441.971\tvalid_1's rmse: 828.054\n",
      "[7500]\ttraining's rmse: 430.902\tvalid_1's rmse: 827.392\n",
      "[8000]\ttraining's rmse: 420.479\tvalid_1's rmse: 827.259\n",
      "[8500]\ttraining's rmse: 410.541\tvalid_1's rmse: 826.724\n",
      "Early stopping, best iteration is:\n",
      "[8670]\ttraining's rmse: 407.258\tvalid_1's rmse: 826.515\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 835.937\tvalid_1's rmse: 888.382\n",
      "[1000]\ttraining's rmse: 736.833\tvalid_1's rmse: 838.751\n",
      "[1500]\ttraining's rmse: 679.669\tvalid_1's rmse: 818.918\n",
      "[2000]\ttraining's rmse: 637.903\tvalid_1's rmse: 807.484\n",
      "[2500]\ttraining's rmse: 604.687\tvalid_1's rmse: 799.349\n",
      "[3000]\ttraining's rmse: 577.354\tvalid_1's rmse: 793.783\n",
      "[3500]\ttraining's rmse: 553.885\tvalid_1's rmse: 790.331\n",
      "[4000]\ttraining's rmse: 533.364\tvalid_1's rmse: 787.61\n",
      "[4500]\ttraining's rmse: 514.885\tvalid_1's rmse: 785.347\n",
      "[5000]\ttraining's rmse: 498.393\tvalid_1's rmse: 783.973\n",
      "[5500]\ttraining's rmse: 483.024\tvalid_1's rmse: 782.808\n",
      "[6000]\ttraining's rmse: 469.118\tvalid_1's rmse: 782.037\n",
      "[6500]\ttraining's rmse: 456.092\tvalid_1's rmse: 781.323\n",
      "[7000]\ttraining's rmse: 444.222\tvalid_1's rmse: 780.918\n",
      "Early stopping, best iteration is:\n",
      "[6917]\ttraining's rmse: 446.108\tvalid_1's rmse: 780.823\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 839.43\tvalid_1's rmse: 853.835\n",
      "[1000]\ttraining's rmse: 740.292\tvalid_1's rmse: 801.436\n",
      "[1500]\ttraining's rmse: 682.901\tvalid_1's rmse: 781.924\n",
      "[2000]\ttraining's rmse: 640.569\tvalid_1's rmse: 771.309\n",
      "[2500]\ttraining's rmse: 607.455\tvalid_1's rmse: 765.076\n",
      "[3000]\ttraining's rmse: 580.273\tvalid_1's rmse: 760.484\n",
      "[3500]\ttraining's rmse: 556.763\tvalid_1's rmse: 757.159\n",
      "[4000]\ttraining's rmse: 536.011\tvalid_1's rmse: 755.007\n",
      "[4500]\ttraining's rmse: 517.741\tvalid_1's rmse: 753.363\n",
      "[5000]\ttraining's rmse: 501.267\tvalid_1's rmse: 752.218\n",
      "[5500]\ttraining's rmse: 485.928\tvalid_1's rmse: 751.137\n",
      "[6000]\ttraining's rmse: 472.136\tvalid_1's rmse: 750.587\n",
      "Early stopping, best iteration is:\n",
      "[6274]\ttraining's rmse: 464.851\tvalid_1's rmse: 750.397\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 830.975\tvalid_1's rmse: 892.037\n",
      "[1000]\ttraining's rmse: 733.071\tvalid_1's rmse: 844.522\n",
      "[1500]\ttraining's rmse: 676.577\tvalid_1's rmse: 825.923\n",
      "[2000]\ttraining's rmse: 635.672\tvalid_1's rmse: 814.687\n",
      "[2500]\ttraining's rmse: 603.07\tvalid_1's rmse: 808.4\n",
      "[3000]\ttraining's rmse: 575.881\tvalid_1's rmse: 803.685\n",
      "[3500]\ttraining's rmse: 552.78\tvalid_1's rmse: 800.589\n",
      "[4000]\ttraining's rmse: 532.182\tvalid_1's rmse: 797.845\n",
      "[4500]\ttraining's rmse: 513.823\tvalid_1's rmse: 796.076\n",
      "[5000]\ttraining's rmse: 497.406\tvalid_1's rmse: 794.534\n",
      "[5500]\ttraining's rmse: 482.645\tvalid_1's rmse: 793.54\n",
      "[6000]\ttraining's rmse: 468.729\tvalid_1's rmse: 792.863\n",
      "[6500]\ttraining's rmse: 455.979\tvalid_1's rmse: 792.395\n",
      "[7000]\ttraining's rmse: 444.025\tvalid_1's rmse: 792.053\n",
      "[7500]\ttraining's rmse: 432.797\tvalid_1's rmse: 792.111\n",
      "Early stopping, best iteration is:\n",
      "[7302]\ttraining's rmse: 437.161\tvalid_1's rmse: 791.956\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 828.113\tvalid_1's rmse: 909.13\n",
      "[1000]\ttraining's rmse: 731.322\tvalid_1's rmse: 857.248\n",
      "[1500]\ttraining's rmse: 676.095\tvalid_1's rmse: 836.883\n",
      "[2000]\ttraining's rmse: 635.146\tvalid_1's rmse: 825.12\n",
      "[2500]\ttraining's rmse: 602.697\tvalid_1's rmse: 818.062\n",
      "[3000]\ttraining's rmse: 575.753\tvalid_1's rmse: 812.838\n",
      "[3500]\ttraining's rmse: 552.328\tvalid_1's rmse: 808.929\n",
      "[4000]\ttraining's rmse: 531.797\tvalid_1's rmse: 806.077\n",
      "[4500]\ttraining's rmse: 513.777\tvalid_1's rmse: 804.534\n",
      "[5000]\ttraining's rmse: 497.116\tvalid_1's rmse: 803.137\n",
      "[5500]\ttraining's rmse: 481.918\tvalid_1's rmse: 801.923\n",
      "[6000]\ttraining's rmse: 468.045\tvalid_1's rmse: 801.386\n",
      "[6500]\ttraining's rmse: 455.131\tvalid_1's rmse: 800.697\n",
      "[7000]\ttraining's rmse: 443.264\tvalid_1's rmse: 800.473\n",
      "Early stopping, best iteration is:\n",
      "[6862]\ttraining's rmse: 446.524\tvalid_1's rmse: 800.459\n",
      "CV Score: 0.90448 \n"
     ]
    }
   ],
   "source": [
    "folds = KFold(n_splits=5,shuffle=True,random_state=2019)\n",
    "oof_lgb = np.zeros(len(X))\n",
    "pred_lgb = np.zeros(len(X_test))\n",
    "start = time.time()\n",
    "for fold_,(trn_idx,val_idx) in enumerate(folds.split(X.values,Y.values)):\n",
    "    print(\"fold n°{}\".format(fold_))\n",
    "    trn_data = lgb.Dataset(X.iloc[trn_idx],label=Y.iloc[trn_idx])\n",
    "    \n",
    "    val_data = lgb.Dataset(X.iloc[val_idx],label=Y.iloc[val_idx])\n",
    "    \n",
    "\n",
    "    num_round = 10000\n",
    "    clf = lgb.train(params,\n",
    "                    trn_data,\n",
    "                    num_round,\n",
    "                    valid_sets = [trn_data, val_data],\n",
    "                    verbose_eval=500,\n",
    "                    early_stopping_rounds = 200)\n",
    "        \n",
    "    oof_lgb[val_idx] = clf.predict(X.iloc[val_idx], num_iteration=clf.best_iteration)\n",
    "    pred_lgb += clf.predict(X_test, num_iteration=clf.best_iteration) / folds.n_splits\n",
    "\n",
    "print(\"CV Score: {:<8.5f}\".format(r2_score( Y, oof_lgb)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def online_score(pred):\n",
    "    print(\"预测结果最大值：{},预测结果最小值：{}\".format(pred.max(),pred.min()))\n",
    "    # a榜测分\n",
    "    conmbine1 = pd.read_csv(\"D:/DataAnalysis/2019未来高校AI挑战赛_城市-房产租金预测/sub_a_913.csv\",engine = \"python\",header=None)\n",
    "    score1 = r2_score(pred, conmbine1.values)\n",
    "    print(\"对比913分数:{}\".format(score1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测结果最大值：17097.799079001084,预测结果最小值：1152.9007407421789\n",
      "对比913分数:0.9782714515371335\n"
     ]
    }
   ],
   "source": [
    "online_score(pred_lgb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
